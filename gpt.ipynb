{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9f0f96ea-8a8a-4adb-91ee-a7ebe18af4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "#import maritalk\n",
    "import openai\n",
    "import pyconll\n",
    "import json\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b282effc-b7cc-450d-b055-49a32e1674d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gptkey2.txt') as f:\n",
    "    gpt_key = f.readlines()[0]\n",
    "openai.api_key = gpt_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd296ef-24e8-482e-9ba4-2d086113d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askGPT2(prompt, temperature=0.7):\n",
    "    retries = 3\n",
    "    while retries > 0:\n",
    "        try:    \n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "        except Exception as e: \n",
    "            if e:\n",
    "                print(e)\n",
    "                retries -= 1\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                raise e\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3e4dfea8-5bfa-4fb4-85f1-8893e3a96990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askGPT(prompt, temperature=0.7):\n",
    "    openai.api_key = gpt_key\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        request_timeout=120,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    time.sleep(2)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18aa7ed7-6050-48cf-9ee8-0a765a71a85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8GriJE6K30LQQvscNDimIKSPIcfIM\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1699030415,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"25 + 27 = 52\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 16,\n",
      "    \"completion_tokens\": 7,\n",
      "    \"total_tokens\": 23\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resp = askGPT(\"Quanto é 25 + 27?\", 0.9)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51ed2ea-b4e2-40c8-b4b8-bf7b90fca22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 + 27 = 52\n"
     ]
    }
   ],
   "source": [
    "a = resp['choices'][0]['message']['content']\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740cc0f-efd8-4799-8adb-f6adc84d0e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4b1a8-04ad-4415-b3ff-4e46f411ec86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b298ad2-f647-469f-916e-0be50bddefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading first 1020 dataset sentences\n",
    "frases = pyconll.load_from_file('data/porttinari-base/Porttinari-base_test.conllu')\n",
    "reviews = []\n",
    "for sent in frases[:1020]:\n",
    "    lista_ud=[]\n",
    "    for token in sent:\n",
    "        lista_ud.append([token.form, token.xpos, token.upos, token.deprel])\n",
    "    reviews.append(lista_ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90ffe5-c3e6-4ffa-9535-9555be3da4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd45ee20-e690-4cec-80c5-83f1fbc95eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Atuando como linguista e sem efetuar correções ou alterações no texto, faça a análise morfossintática das frases seguindo a anotação UD (Universal Dependencies):'},\n",
       " {'role': 'user', 'content': 'O Capitão América também bajulou o tucano .'},\n",
       " {'role': 'system',\n",
       "  'content': 'O/DET Capitão/PROPN América/PROPN também/ADV bajulou/VERB o/DET tucano/NOUN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'A Odebrecht pagou 300 % a mais pelo por o direito de explorar o aeroporto do de o Galeão .'},\n",
       " {'role': 'system',\n",
       "  'content': 'A/DET Odebrecht/PROPN pagou/VERB 300/NUM %/SYM a/ADP mais/ADV pelo/None por/ADP o/DET direito/NOUN de/ADP explorar/VERB o/DET aeroporto/NOUN do/None de/ADP o/DET Galeão/PROPN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'No Em o começo do de o século , a JBS/Friboi chegava ao a o grupo das de as 400 maiores .'},\n",
       " {'role': 'system',\n",
       "  'content': 'No/None Em/ADP o/DET começo/NOUN do/None de/ADP o/DET século/NOUN ,/PUNCT a/DET JBS/Friboi/PROPN chegava/VERB ao/None a/ADP o/DET grupo/NOUN das/None de/ADP as/DET 400/NUM maiores/ADJ ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Os sons indesejáveis emitidos por uma porta , por exemplo , são eliminados por R$ 150 .'},\n",
       " {'role': 'system',\n",
       "  'content': 'Os/DET sons/NOUN indesejáveis/ADJ emitidos/VERB por/ADP uma/DET porta/NOUN ,/PUNCT por/ADP exemplo/NOUN ,/PUNCT são/AUX eliminados/VERB por/ADP R$/SYM 150/NUM ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Que foi herança do de o PT , que nos deixou esse rombo , disse Doria .'},\n",
       " {'role': 'system',\n",
       "  'content': 'Que/PRON foi/AUX herança/NOUN do/None de/ADP o/DET PT/PROPN ,/PUNCT que/PRON nos/PRON deixou/VERB esse/DET rombo/NOUN ,/PUNCT disse/VERB Doria/PROPN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'O departamento médico santista também já colocou o atleta para ter o acompanhamento de uma psicóloga .'},\n",
       " {'role': 'system',\n",
       "  'content': 'O/DET departamento/NOUN médico/ADJ santista/ADJ também/ADV já/ADV colocou/VERB o/DET atleta/NOUN para/ADP ter/VERB o/DET acompanhamento/NOUN de/ADP uma/DET psicóloga/NOUN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Por que é mais difícil para as mulheres lutar contra alcoolismo e dependência às a as drogas ?'},\n",
       " {'role': 'system',\n",
       "  'content': 'Por/ADP que/PRON é/AUX mais/ADV difícil/ADJ para/ADP as/DET mulheres/NOUN lutar/VERB contra/ADP alcoolismo/NOUN e/CCONJ dependência/NOUN às/None a/ADP as/DET drogas/NOUN ?/PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Outra etiqueta das de as mais clássicas do de o calendário , a Bottega Venetta construiu com base nas em as pintas de leopardo a imagem de amazona moderna .'},\n",
       " {'role': 'system',\n",
       "  'content': 'Outra/DET etiqueta/NOUN das/None de/ADP as/PRON mais/ADV clássicas/ADJ do/None de/ADP o/DET calendário/NOUN ,/PUNCT a/DET Bottega/PROPN Venetta/PROPN construiu/VERB com/ADP base/NOUN nas/None em/ADP as/DET pintas/NOUN de/ADP leopardo/NOUN a/DET imagem/NOUN de/ADP amazona/NOUN moderna/ADJ ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Não é biodegradável e , para produzí-lo produzir lo , é necessário expandir ainda mais a agricultura da de a cana .'},\n",
       " {'role': 'system',\n",
       "  'content': 'Não/ADV é/AUX biodegradável/ADJ e/CCONJ ,/PUNCT para/ADP produzí-lo/None produzir/VERB lo/PRON ,/PUNCT é/AUX necessário/ADJ expandir/VERB ainda/ADV mais/ADV a/DET agricultura/NOUN da/None de/ADP a/DET cana/NOUN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': '\" Temos segurança de que ( ... ) são íntegros \" , diz o texto .'},\n",
       " {'role': 'system',\n",
       "  'content': '\"/PUNCT Temos/VERB segurança/NOUN de/ADP que/SCONJ (/PUNCT .../PUNCT )/PUNCT são/AUX íntegros/ADJ \"/PUNCT ,/PUNCT diz/VERB o/DET texto/NOUN ./PUNCT'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptStart = []\n",
    "promptStart.append({\n",
    "    \"role\": \"system\",\n",
    "    \"content\":\"Atuando como linguista e sem efetuar correções ou alterações no texto, faça a análise morfossintática das frases seguindo a anotação UD (Universal Dependencies):\"\n",
    "})\n",
    "for review in reviews[:10]:\n",
    "    entrada = \"\"\n",
    "    saida = \"\"\n",
    "    for token in review:\n",
    "        if not token[2]:\n",
    "            token[2] = 'None'\n",
    "        entrada += token[0] + ' '\n",
    "        saida += token[0] + '/' + token[2] + ' '\n",
    "    entrada = entrada.strip()\n",
    "    saida = saida.strip()\n",
    "    promptStart.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": entrada\n",
    "    })\n",
    "    promptStart.append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": saida\n",
    "    })\n",
    "promptStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15000900-c35e-4fd8-832d-0e43b824ce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atuando como linguista e sem efetuar correções ou alterações no texto, faça a análise morfossintática das frases seguindo a anotação UD (Universal Dependencies) conforme os exemplos abaixo:\n",
      "\n",
      "Entrada: O Capitão América também bajulou o tucano .\n",
      "Saida: O/DET Capitão/PROPN América/PROPN também/ADV bajulou/VERB o/DET tucano/NOUN ./PUNCT\n",
      "\n",
      "Entrada: A Odebrecht pagou 300 % a mais pelo por o direito de explorar o aeroporto do de o Galeão .\n",
      "Saida: A/DET Odebrecht/PROPN pagou/VERB 300/NUM %/SYM a/ADP mais/ADV pelo/None por/ADP o/DET direito/NOUN de/ADP explorar/VERB o/DET aeroporto/NOUN do/None de/ADP o/DET Galeão/PROPN ./PUNCT\n",
      "\n",
      "Entrada: No Em o começo do de o século , a JBS/Friboi chegava ao a o grupo das de as 400 maiores .\n",
      "Saida: No/None Em/ADP o/DET começo/NOUN do/None de/ADP o/DET século/NOUN ,/PUNCT a/DET JBS/Friboi/PROPN chegava/VERB ao/None a/ADP o/DET grupo/NOUN das/None de/ADP as/DET 400/NUM maiores/ADJ ./PUNCT\n",
      "\n",
      "Entrada: Os sons indesejáveis emitidos por uma porta , por exemplo , são eliminados por R$ 150 .\n",
      "Saida: Os/DET sons/NOUN indesejáveis/ADJ emitidos/VERB por/ADP uma/DET porta/NOUN ,/PUNCT por/ADP exemplo/NOUN ,/PUNCT são/AUX eliminados/VERB por/ADP R$/SYM 150/NUM ./PUNCT\n",
      "\n",
      "Entrada: Que foi herança do de o PT , que nos deixou esse rombo , disse Doria .\n",
      "Saida: Que/PRON foi/AUX herança/NOUN do/None de/ADP o/DET PT/PROPN ,/PUNCT que/PRON nos/PRON deixou/VERB esse/DET rombo/NOUN ,/PUNCT disse/VERB Doria/PROPN ./PUNCT\n",
      "\n",
      "Entrada: O departamento médico santista também já colocou o atleta para ter o acompanhamento de uma psicóloga .\n",
      "Saida: O/DET departamento/NOUN médico/ADJ santista/ADJ também/ADV já/ADV colocou/VERB o/DET atleta/NOUN para/ADP ter/VERB o/DET acompanhamento/NOUN de/ADP uma/DET psicóloga/NOUN ./PUNCT\n",
      "\n",
      "Entrada: Por que é mais difícil para as mulheres lutar contra alcoolismo e dependência às a as drogas ?\n",
      "Saida: Por/ADP que/PRON é/AUX mais/ADV difícil/ADJ para/ADP as/DET mulheres/NOUN lutar/VERB contra/ADP alcoolismo/NOUN e/CCONJ dependência/NOUN às/None a/ADP as/DET drogas/NOUN ?/PUNCT\n",
      "\n",
      "Entrada: Outra etiqueta das de as mais clássicas do de o calendário , a Bottega Venetta construiu com base nas em as pintas de leopardo a imagem de amazona moderna .\n",
      "Saida: Outra/DET etiqueta/NOUN das/None de/ADP as/PRON mais/ADV clássicas/ADJ do/None de/ADP o/DET calendário/NOUN ,/PUNCT a/DET Bottega/PROPN Venetta/PROPN construiu/VERB com/ADP base/NOUN nas/None em/ADP as/DET pintas/NOUN de/ADP leopardo/NOUN a/DET imagem/NOUN de/ADP amazona/NOUN moderna/ADJ ./PUNCT\n",
      "\n",
      "Entrada: Não é biodegradável e , para produzí-lo produzir lo , é necessário expandir ainda mais a agricultura da de a cana .\n",
      "Saida: Não/ADV é/AUX biodegradável/ADJ e/CCONJ ,/PUNCT para/ADP produzí-lo/None produzir/VERB lo/PRON ,/PUNCT é/AUX necessário/ADJ expandir/VERB ainda/ADV mais/ADV a/DET agricultura/NOUN da/None de/ADP a/DET cana/NOUN ./PUNCT\n",
      "\n",
      "Entrada: \" Temos segurança de que ( ... ) são íntegros \" , diz o texto .\n",
      "Saida: \"/PUNCT Temos/VERB segurança/NOUN de/ADP que/SCONJ (/PUNCT .../PUNCT )/PUNCT são/AUX íntegros/ADJ \"/PUNCT ,/PUNCT diz/VERB o/DET texto/NOUN ./PUNCT\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head = \"Atuando como linguista e sem efetuar correções ou alterações no texto, faça a análise morfossintática das frases seguindo a anotação UD (Universal Dependencies) conforme os exemplos abaixo:\\n\\n\"\n",
    "promptStart = head\n",
    "for review in reviews[:10]:\n",
    "    entrada = \"Entrada: \"\n",
    "    saida  = \"Saida: \"\n",
    "    for token in review:\n",
    "        if not token[2]:\n",
    "            token[2] = 'None'\n",
    "        entrada += token[0] + ' '\n",
    "        saida += token[0] + '/' + token[2] + ' '\n",
    "    entrada = entrada.strip()\n",
    "    saida = saida.strip()\n",
    "    promptStart += entrada + \"\\n\" + saida + \"\\n\\n\"\n",
    "print(promptStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59eb7afe-ec31-4c64-a5ab-d9034620af79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 8113.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.89      0.94      0.92        18\n",
      "         ADP       0.91      0.96      0.93        45\n",
      "         ADV       0.90      0.69      0.78        13\n",
      "         AUX       0.94      0.94      0.94        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.94      0.94      0.94        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       1.00      0.95      0.98        62\n",
      "         NUM       1.00      1.00      1.00         5\n",
      "        None       0.94      0.71      0.81        21\n",
      "        PRON       0.70      0.88      0.78        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       0.62      1.00      0.77         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.94      0.97      0.96        35\n",
      "\n",
      "    accuracy                           0.93       315\n",
      "   macro avg       0.92      0.93      0.92       315\n",
      "weighted avg       0.93      0.93      0.93       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "temp 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [04:36<00:00, 13.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.89      0.94      0.92        18\n",
      "         ADP       0.88      0.96      0.91        45\n",
      "         ADV       0.90      0.69      0.78        13\n",
      "         AUX       0.88      0.94      0.91        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.93      0.91      0.92        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       1.00      0.95      0.98        62\n",
      "         NUM       1.00      1.00      1.00         5\n",
      "        None       0.93      0.62      0.74        21\n",
      "        PRON       0.67      0.88      0.76        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       0.62      1.00      0.77         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.94      0.94      0.94        35\n",
      "\n",
      "    accuracy                           0.91       315\n",
      "   macro avg       0.91      0.92      0.91       315\n",
      "weighted avg       0.92      0.91      0.91       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "temp 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [05:27<00:00, 16.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.89      0.94      0.92        18\n",
      "         ADP       0.90      0.96      0.92        45\n",
      "         ADV       0.90      0.69      0.78        13\n",
      "         AUX       0.94      0.94      0.94        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.94      0.94      0.94        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       1.00      0.92      0.96        62\n",
      "         NUM       0.71      1.00      0.83         5\n",
      "        None       0.93      0.67      0.78        21\n",
      "        PRON       0.70      0.88      0.78        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       0.62      1.00      0.77         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.94      0.97      0.96        35\n",
      "\n",
      "    accuracy                           0.92       315\n",
      "   macro avg       0.90      0.93      0.90       315\n",
      "weighted avg       0.93      0.92      0.92       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "temp 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [04:56<00:00, 14.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.89      0.94      0.92        18\n",
      "         ADP       0.89      0.93      0.91        45\n",
      "         ADV       0.90      0.69      0.78        13\n",
      "         AUX       0.94      0.94      0.94        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.93      0.91      0.92        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       1.00      0.94      0.97        62\n",
      "         NUM       0.71      1.00      0.83         5\n",
      "        None       0.93      0.67      0.78        21\n",
      "        PRON       0.70      0.88      0.78        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       0.56      1.00      0.71         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.94      0.97      0.96        35\n",
      "\n",
      "    accuracy                           0.91       315\n",
      "   macro avg       0.89      0.92      0.90       315\n",
      "weighted avg       0.92      0.91      0.92       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "temp 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [05:00<00:00, 15.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.85      0.94      0.89        18\n",
      "         ADP       0.86      0.93      0.89        45\n",
      "         ADV       0.90      0.69      0.78        13\n",
      "         AUX       0.79      0.94      0.86        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.93      0.91      0.92        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       1.00      0.95      0.98        62\n",
      "         NUM       1.00      1.00      1.00         5\n",
      "        None       0.87      0.62      0.72        21\n",
      "        PRON       0.68      0.81      0.74        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       0.50      0.80      0.62         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.94      0.89      0.91        35\n",
      "\n",
      "    accuracy                           0.90       315\n",
      "   macro avg       0.89      0.90      0.89       315\n",
      "weighted avg       0.91      0.90      0.90       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "temp 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [05:03<00:00, 15.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.89      0.94      0.92        18\n",
      "         ADP       0.93      0.96      0.95        45\n",
      "         ADV       1.00      0.69      0.82        13\n",
      "         AUX       0.88      0.94      0.91        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.94      0.96      0.95        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       1.00      0.92      0.96        62\n",
      "         NUM       0.71      1.00      0.83         5\n",
      "        None       0.94      0.76      0.84        21\n",
      "        PRON       0.75      0.94      0.83        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       0.62      1.00      0.77         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.94      0.94      0.94        35\n",
      "\n",
      "    accuracy                           0.93       315\n",
      "   macro avg       0.91      0.94      0.91       315\n",
      "weighted avg       0.94      0.93      0.93       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "temp 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [05:03<00:00, 15.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.89      0.94      0.92        18\n",
      "         ADP       0.91      0.93      0.92        45\n",
      "         ADV       0.90      0.69      0.78        13\n",
      "         AUX       0.88      0.94      0.91        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.96      0.94      0.95        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       1.00      0.95      0.98        62\n",
      "         NUM       0.83      1.00      0.91         5\n",
      "        None       0.88      0.71      0.79        21\n",
      "        PRON       0.74      0.88      0.80        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       0.56      1.00      0.71         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.94      0.94      0.94        35\n",
      "\n",
      "    accuracy                           0.92       315\n",
      "   macro avg       0.90      0.93      0.91       315\n",
      "weighted avg       0.93      0.92      0.92       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "temp 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [05:00<00:00, 15.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.89      0.94      0.92        18\n",
      "         ADP       0.89      0.91      0.90        45\n",
      "         ADV       0.91      0.77      0.83        13\n",
      "         AUX       0.83      0.94      0.88        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.93      0.87      0.90        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       1.00      0.97      0.98        62\n",
      "         NUM       1.00      1.00      1.00         5\n",
      "        None       0.88      0.67      0.76        21\n",
      "        PRON       0.64      0.88      0.74        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       0.62      1.00      0.77         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.94      0.91      0.93        35\n",
      "\n",
      "    accuracy                           0.91       315\n",
      "   macro avg       0.90      0.92      0.91       315\n",
      "weighted avg       0.92      0.91      0.91       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "temp 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [04:55<00:00, 14.79s/it]\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.85      0.94      0.89        18\n",
      "         ADP       0.93      0.93      0.93        45\n",
      "      ADPles       0.00      0.00      0.00         0\n",
      "         ADV       0.89      0.62      0.73        13\n",
      "         AUX       0.83      0.94      0.88        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.95      0.89      0.92        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       0.98      0.94      0.96        62\n",
      "         NUM       1.00      1.00      1.00         5\n",
      "        None       0.89      0.76      0.82        21\n",
      "        PRON       0.62      0.81      0.70        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       0.56      1.00      0.71         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.94      0.91      0.93        35\n",
      "\n",
      "    accuracy                           0.90       315\n",
      "   macro avg       0.84      0.86      0.84       315\n",
      "weighted avg       0.92      0.90      0.91       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n",
      "temp 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [04:58<00:00, 14.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 315 pred 315 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.77      0.94      0.85        18\n",
      "         ADP       0.90      0.96      0.92        45\n",
      "      ADPles       0.00      0.00      0.00         0\n",
      "         ADV       1.00      0.69      0.82        13\n",
      "         AUX       0.87      0.81      0.84        16\n",
      "       CCONJ       1.00      1.00      1.00         8\n",
      "         DET       0.93      0.85      0.89        47\n",
      "        INTJ       1.00      1.00      1.00         1\n",
      "        NOUN       1.00      0.90      0.95        62\n",
      "         NUM       0.71      1.00      0.83         5\n",
      "        None       0.88      0.67      0.76        21\n",
      "        PRON       0.57      0.81      0.67        16\n",
      "       PROPN       1.00      1.00      1.00        22\n",
      "       SCONJ       1.00      1.00      1.00         5\n",
      "         SYM       1.00      1.00      1.00         1\n",
      "        VERB       0.87      0.94      0.90        35\n",
      "\n",
      "    accuracy                           0.89       315\n",
      "   macro avg       0.84      0.85      0.84       315\n",
      "weighted avg       0.91      0.89      0.89       315\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "punctList = ['\"', ',', '.', '[', ']', '?','!']\n",
    "for temp in range(0,10):\n",
    "    if temp:\n",
    "        temp = temp/10\n",
    "    print('temp',temp)\n",
    "    gold = []\n",
    "    pred = []\n",
    "    totalTries = []\n",
    "    errors = 0\n",
    "    for revID, review in enumerate(tqdm(reviews[20:40])):\n",
    "        prompt = promptStart\n",
    "        entrada = \"Entrada: \"\n",
    "        saida  = \"Saida: \"        \n",
    "        goldSent = []\n",
    "        goldTokens = []\n",
    "        for token in review:\n",
    "            if not token[2]:\n",
    "                token[2] = 'None'\n",
    "            if token[0] not in punctList:\n",
    "                gold.append(token[2])\n",
    "                goldSent.append(token[2])\n",
    "                goldTokens.append(token[0])\n",
    "            entrada += token[0] + ' '\n",
    "            saida += token[0] + '/' + token[2] + ' '\n",
    "        entrada = entrada.strip()\n",
    "        saida = saida.strip()\n",
    "        prompt += entrada + \"\\nSaída: \"        \n",
    "        #prompt.append({\n",
    "        #    \"role\": \"user\",\n",
    "        #    \"content\": entrada\n",
    "        #})\n",
    "        fileName = f'resultados/gpt/gpt_t{temp}_{revID}.json'\n",
    "        if os.path.isfile(fileName):\n",
    "            with open(fileName) as file:\n",
    "                tagsPred = json.load(file)\n",
    "        else:            \n",
    "            tries = 0\n",
    "            while True:\n",
    "                if tries > 10:\n",
    "                    errors += 1\n",
    "                    totalTries.append(tries)\n",
    "                    with open(f'resultados/gpt/gpt_test_erro_t{temp}_{revID}.log', 'w') as f:\n",
    "                        f.write(prompt)\n",
    "                        f.write('======')\n",
    "                        f.write(answer+'\\n\\n')\n",
    "                        f.write('gold'+ str(goldSent) + str(len(goldSent))+'\\n')\n",
    "                        f.write(str(goldTokens)+'\\n')\n",
    "                        f.write('pred' + str(tagsSent) + str(len(tagsSent))+'\\n')\n",
    "                        f.write(str(tokens)+'\\n')\n",
    "                        f.write('\\n\\n')\n",
    "                    tagsPred = ['None'] * len(goldSent)\n",
    "                    #dsdaasd\n",
    "                    break\n",
    "                resp = askGPT(prompt, temperature=temp)\n",
    "                answer = resp['choices'][0]['message']['content']\n",
    "                tries += 1\n",
    "                try:\n",
    "                    tokens = [token for token in answer.split(' ') if token[0] not in punctList]\n",
    "                    tokensSent = []\n",
    "                    tagsSent = []\n",
    "                    for token in tokens:\n",
    "                        if '/' in token:\n",
    "                            tagsSent.append(token.split('/')[1])\n",
    "                            tokensSent.append(token.split('/')[0])\n",
    "                        else:\n",
    "                            tagsSent.append('None')\n",
    "                            tokensSent.append(token)\n",
    "                except Exception as error:\n",
    "                    continue\n",
    "                idx = 0\n",
    "                erroIdx = 0\n",
    "                tagsPred = []\n",
    "                for token, tag in zip(goldTokens, goldSent):\n",
    "                    if idx >= len(tokensSent):\n",
    "                        tagsPred.append('None')\n",
    "                        erroIdx += 1\n",
    "                        continue           \n",
    "                    if tokensSent[idx].lower() == token.lower():\n",
    "                        tagsPred.append(tagsSent[idx])\n",
    "                    else:\n",
    "                        if idx == 0:\n",
    "                            while (tokensSent[idx].lower() != token.lower() and idx < 5):\n",
    "                                idx += 1\n",
    "                                if idx >= len(tokensSent):\n",
    "                                    idx -= 1\n",
    "                                    break\n",
    "                        if tokensSent[idx].lower() == token.lower():\n",
    "                            tagsPred.append(tagsSent[idx])\n",
    "                        else:\n",
    "                            tagsPred.append('None')\n",
    "                            erroIdx += 1\n",
    "                            continue\n",
    "                    idx += 1\n",
    "                if len(tagsPred) == len(goldSent) and erroIdx < 10:\n",
    "                    totalTries.append(tries)\n",
    "                    break\n",
    "        with open(fileName, 'w') as f:\n",
    "            json.dump(tagsPred, f)\n",
    "        pred += tagsPred\n",
    "        #ksdfhfkdh\n",
    "        #print('=======')\n",
    "    print('gold',len(gold),'pred',len(pred),'errors',errors)\n",
    "    with open(f'resultados/gpt_test_t{temp}.json', 'w') as f:\n",
    "        json.dump(pred, f)\n",
    "    #with open(f'resultados/gold.json', 'w') as f:\n",
    "    #    json.dump(gold, f)\n",
    "    print(metrics.classification_report(gold, pred))\n",
    "    print(\"\\n\\n\\n\\n######\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e7319-56c5-4748-98b1-9b9137f0f82f",
   "metadata": {},
   "source": [
    "## 0.0 full experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b0356175-39ce-4d51-a624-d4122b6f31f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [14:56<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 18690 pred 18690 errors 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           \"       0.00      0.00      0.00         0\n",
      "           (       0.00      0.00      0.00         0\n",
      "           )       0.00      0.00      0.00         0\n",
      "         ADJ       0.82      0.97      0.89       996\n",
      "         ADP       0.85      0.93      0.89      2943\n",
      "         ADV       0.91      0.87      0.89       759\n",
      "         AUX       0.79      0.89      0.84       592\n",
      "       CCONJ       0.99      0.95      0.97       497\n",
      "         DET       0.91      0.94      0.93      2880\n",
      "        INTJ       0.75      1.00      0.86         3\n",
      "        NOUN       0.98      0.96      0.97      3757\n",
      "         NUM       0.96      0.87      0.91       364\n",
      "        None       0.83      0.58      0.68      1208\n",
      "        PRON       0.81      0.78      0.80       771\n",
      "       PROPN       0.98      0.93      0.95      1290\n",
      "       PUNCT       1.00      0.87      0.93       222\n",
      "       SCONJ       0.65      0.97      0.78       277\n",
      "         SYM       1.00      0.95      0.97        74\n",
      "        VERB       0.95      0.91      0.93      2024\n",
      "           X       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.90     18690\n",
      "   macro avg       0.71      0.72      0.71     18690\n",
      "weighted avg       0.91      0.90      0.90     18690\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "######\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mateus.machado/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "punctList = ['\"', ',', '.', '[', ']', '?','!']\n",
    "for temp in range(0,1):\n",
    "    if temp:\n",
    "        temp = temp/10\n",
    "    print('temp',temp)\n",
    "    gold = []\n",
    "    pred = []\n",
    "    totalTries = []\n",
    "    errors = 0\n",
    "    for revID, review in enumerate(tqdm(reviews[20:])):\n",
    "        prompt = promptStart\n",
    "        entrada = \"Entrada: \"\n",
    "        saida  = \"Saida: \"        \n",
    "        goldSent = []\n",
    "        goldTokens = []\n",
    "        for token in review:\n",
    "            if not token[2]:\n",
    "                token[2] = 'None'\n",
    "            if token[0] not in punctList:\n",
    "                gold.append(token[2])\n",
    "                goldSent.append(token[2])\n",
    "                goldTokens.append(token[0])\n",
    "            entrada += token[0] + ' '\n",
    "            saida += token[0] + '/' + token[2] + ' '\n",
    "        entrada = entrada.strip()\n",
    "        saida = saida.strip()\n",
    "        prompt += entrada + \"\\nSaída: \"        \n",
    "        #prompt.append({\n",
    "        #    \"role\": \"user\",\n",
    "        #    \"content\": entrada\n",
    "        #})\n",
    "        fileName = f'resultados/gpt/gpt_t{temp}_{revID}.json'\n",
    "        if os.path.isfile(fileName):\n",
    "            with open(fileName) as file:\n",
    "                tagsPred = json.load(file)\n",
    "        else:            \n",
    "            tries = 0\n",
    "            while True:\n",
    "                if tries > 10:\n",
    "                    errors += 1\n",
    "                    totalTries.append(tries)\n",
    "                    with open(f'resultados/gpt/gpt_erro_t{temp}_{revID}.log', 'w') as f:\n",
    "                        f.write(prompt)\n",
    "                        f.write('======')\n",
    "                        f.write(answer+'\\n\\n')\n",
    "                        f.write('gold'+ str(goldSent) + str(len(goldSent))+'\\n')\n",
    "                        f.write(str(goldTokens)+'\\n')\n",
    "                        f.write('pred' + str(tagsSent) + str(len(tagsSent))+'\\n')\n",
    "                        f.write(str(tokens)+'\\n')\n",
    "                        f.write('\\n\\n')\n",
    "                    tagsPred = ['None'] * len(goldSent)\n",
    "                    #dsdaasd\n",
    "                    break\n",
    "                resp = askGPT(prompt, temperature=temp)\n",
    "                answer = resp['choices'][0]['message']['content']\n",
    "                tries += 1\n",
    "                try:\n",
    "                    tokens = [token for token in answer.split(' ') if token[0] not in punctList]\n",
    "                    tokensSent = []\n",
    "                    tagsSent = []\n",
    "                    for token in tokens:\n",
    "                        if '/' in token:\n",
    "                            tagsSent.append(token.split('/')[1])\n",
    "                            tokensSent.append(token.split('/')[0])\n",
    "                        else:\n",
    "                            tagsSent.append('None')\n",
    "                            tokensSent.append(token)\n",
    "                except Exception as error:\n",
    "                    continue\n",
    "                idx = 0\n",
    "                erroIdx = 0\n",
    "                tagsPred = []\n",
    "                for token, tag in zip(goldTokens, goldSent):\n",
    "                    if idx >= len(tokensSent):\n",
    "                        tagsPred.append('None')\n",
    "                        erroIdx += 1\n",
    "                        continue           \n",
    "                    if tokensSent[idx].lower() == token.lower():\n",
    "                        tagsPred.append(tagsSent[idx])\n",
    "                    else:\n",
    "                        if idx == 0:\n",
    "                            while (tokensSent[idx].lower() != token.lower() and idx < 5):\n",
    "                                idx += 1\n",
    "                                if idx >= len(tokensSent):\n",
    "                                    idx -= 1\n",
    "                                    break\n",
    "                        if tokensSent[idx].lower() == token.lower():\n",
    "                            tagsPred.append(tagsSent[idx])\n",
    "                        else:\n",
    "                            tagsPred.append('None')\n",
    "                            erroIdx += 1\n",
    "                            continue\n",
    "                    idx += 1\n",
    "                if len(tagsPred) == len(goldSent) and erroIdx < 10:\n",
    "                    totalTries.append(tries)\n",
    "                    break\n",
    "        with open(fileName, 'w') as f:\n",
    "            json.dump(tagsPred, f)\n",
    "        pred += tagsPred\n",
    "        #ksdfhfkdh\n",
    "        #print('=======')\n",
    "    print('gold',len(gold),'pred',len(pred),'errors',errors)\n",
    "    with open(f'resultados/gpt_t{temp}.json', 'w') as f:\n",
    "        json.dump(pred, f)\n",
    "    #with open(f'resultados/gold.json', 'w') as f:\n",
    "    #    json.dump(gold, f)\n",
    "    print(metrics.classification_report(gold, pred))\n",
    "    print(\"\\n\\n\\n\\n######\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "70d3a84a-9fa9-455c-97a3-a9381e165eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(totalTries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eca85b87-8bed-42cc-bbce-2320c3e89263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18690"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6a5389a7-7a18-4a90-a8bc-89bda8dafbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18690"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a2f31b1e-4110-43a5-987b-fed54e66c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'resultados/gpt_final.json', 'w') as f:\n",
    "    json.dump(pred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12334c-dd9e-49c9-88f0-0796b33ea2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e7f09-d1e2-4fe9-936c-2c4f98b6a853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cdcf89f9-c6a0-44bf-9788-f759adc56b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3265"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2073a1e5-8695-4802-ae2a-9d46d7fa661a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Atuando como linguista e sem efetuar correções ou alterações no texto, faça a análise morfossintática das frases seguindo a anotação UD (Universal Dependencies) conforme os exemplos abaixo:\\n\\nEntrada: O Capitão América também bajulou o tucano .\\nSaida: O/DET Capitão/PROPN América/PROPN também/ADV bajulou/VERB o/DET tucano/NOUN ./PUNCT\\n\\nEntrada: A Odebrecht pagou 300 % a mais pelo por o direito de explorar o aeroporto do de o Galeão .\\nSaida: A/DET Odebrecht/PROPN pagou/VERB 300/NUM %/SYM a/ADP mais/ADV pelo/None por/ADP o/DET direito/NOUN de/ADP explorar/VERB o/DET aeroporto/NOUN do/None de/ADP o/DET Galeão/PROPN ./PUNCT\\n\\nEntrada: No Em o começo do de o século , a JBS/Friboi chegava ao a o grupo das de as 400 maiores .\\nSaida: No/None Em/ADP o/DET começo/NOUN do/None de/ADP o/DET século/NOUN ,/PUNCT a/DET JBS/Friboi/PROPN chegava/VERB ao/None a/ADP o/DET grupo/NOUN das/None de/ADP as/DET 400/NUM maiores/ADJ ./PUNCT\\n\\nEntrada: Os sons indesejáveis emitidos por uma porta , por exemplo , são eliminados por R$ 150 .\\nSaida: Os/DET sons/NOUN indesejáveis/ADJ emitidos/VERB por/ADP uma/DET porta/NOUN ,/PUNCT por/ADP exemplo/NOUN ,/PUNCT são/AUX eliminados/VERB por/ADP R$/SYM 150/NUM ./PUNCT\\n\\nEntrada: Que foi herança do de o PT , que nos deixou esse rombo , disse Doria .\\nSaida: Que/PRON foi/AUX herança/NOUN do/None de/ADP o/DET PT/PROPN ,/PUNCT que/PRON nos/PRON deixou/VERB esse/DET rombo/NOUN ,/PUNCT disse/VERB Doria/PROPN ./PUNCT\\n\\nEntrada: O departamento médico santista também já colocou o atleta para ter o acompanhamento de uma psicóloga .\\nSaida: O/DET departamento/NOUN médico/ADJ santista/ADJ também/ADV já/ADV colocou/VERB o/DET atleta/NOUN para/ADP ter/VERB o/DET acompanhamento/NOUN de/ADP uma/DET psicóloga/NOUN ./PUNCT\\n\\nEntrada: Por que é mais difícil para as mulheres lutar contra alcoolismo e dependência às a as drogas ?\\nSaida: Por/ADP que/PRON é/AUX mais/ADV difícil/ADJ para/ADP as/DET mulheres/NOUN lutar/VERB contra/ADP alcoolismo/NOUN e/CCONJ dependência/NOUN às/None a/ADP as/DET drogas/NOUN ?/PUNCT\\n\\nEntrada: Outra etiqueta das de as mais clássicas do de o calendário , a Bottega Venetta construiu com base nas em as pintas de leopardo a imagem de amazona moderna .\\nSaida: Outra/DET etiqueta/NOUN das/None de/ADP as/PRON mais/ADV clássicas/ADJ do/None de/ADP o/DET calendário/NOUN ,/PUNCT a/DET Bottega/PROPN Venetta/PROPN construiu/VERB com/ADP base/NOUN nas/None em/ADP as/DET pintas/NOUN de/ADP leopardo/NOUN a/DET imagem/NOUN de/ADP amazona/NOUN moderna/ADJ ./PUNCT\\n\\nEntrada: Não é biodegradável e , para produzí-lo produzir lo , é necessário expandir ainda mais a agricultura da de a cana .\\nSaida: Não/ADV é/AUX biodegradável/ADJ e/CCONJ ,/PUNCT para/ADP produzí-lo/None produzir/VERB lo/PRON ,/PUNCT é/AUX necessário/ADJ expandir/VERB ainda/ADV mais/ADV a/DET agricultura/NOUN da/None de/ADP a/DET cana/NOUN ./PUNCT\\n\\nEntrada: \" Temos segurança de que ( ... ) são íntegros \" , diz o texto .\\nSaida: \"/PUNCT Temos/VERB segurança/NOUN de/ADP que/SCONJ (/PUNCT .../PUNCT )/PUNCT são/AUX íntegros/ADJ \"/PUNCT ,/PUNCT diz/VERB o/DET texto/NOUN ./PUNCT\\n\\nEntrada: Não será empreitada simples , como mostra a escolha , divulgada neste em este domingo ( 17 ) , do de o patriarca José Batista Sobrinho como novo diretor-executivo .\\nSaída: '"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9d0d4-4376-4bb6-b2bb-9a9dcaa8fd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdb0eb-9283-4ea5-918a-4111125a2c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0937df-a07c-4652-a7bd-094873f653e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16a6aeab-2fef-4297-9823-68197e2d462c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON', 'PRON', 'AUX', 'VERB', 'NOUN', 'CCONJ', 'AUX', 'VERB', 'DET', 'NOUN']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e56d5d-9955-4b78-b9b6-7cea87a06324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2ecf3-eebb-4926-a4d6-75ac2216dc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7962653-1017-4a76-a87f-5e69fb7171f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1555.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold 10 pred 7 errors 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10, 7]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(pred, f)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m#with open(f'resultados/gold.json', 'w') as f:\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#    json.dump(gold, f)\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m######\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venvs/propor/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2539\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2406\u001b[0m     {\n\u001b[1;32m   2407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2431\u001b[0m ):\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2433\u001b[0m \n\u001b[1;32m   2434\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2539\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2542\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/venvs/propor/lib/python3.9/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venvs/propor/lib/python3.9/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10, 7]"
     ]
    }
   ],
   "source": [
    "punctList = ['\"', ',', '.', '[', ']', '?','!']\n",
    "for temp in range(0,1):\n",
    "    if temp:\n",
    "        temp = temp/10\n",
    "    print('temp',temp)\n",
    "    gold = []\n",
    "    pred = []\n",
    "    totalTries = []\n",
    "    errors = 0\n",
    "    for revID, review in enumerate(tqdm(reviews[21:22])):\n",
    "        prompt = promptStart.copy()\n",
    "        goldSent = []\n",
    "        goldTokens = []\n",
    "        for token in review:\n",
    "            if not token[2]:\n",
    "                token[2] = 'None'\n",
    "            if token[0] not in punctList:\n",
    "                gold.append(token[2])\n",
    "                goldSent.append(token[2])\n",
    "                goldTokens.append(token[0])\n",
    "            entrada += token[0] + ' '\n",
    "            saida += token[0] + '/' + token[2] + ' '\n",
    "        entrada = entrada.strip()\n",
    "        saida = saida.strip()\n",
    "        prompt.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": entrada\n",
    "        })\n",
    "        fileName = f'resultados/gpt/gpt_t{temp}_{revID}.json'\n",
    "        if os.path.isfile(fileName):\n",
    "            with open(fileName) as file:\n",
    "                tagsPred = json.load(file)\n",
    "        else:            \n",
    "            tries = 0\n",
    "            while True:\n",
    "                if tries > 0:\n",
    "                    errors += 1\n",
    "                    totalTries.append(tries)\n",
    "                    with open(f'resultados/gpt/gpt_test_erro_t{temp}_{revID}.log', 'w') as f:\n",
    "                        f.write(prompt)\n",
    "                        f.write('======')\n",
    "                        f.write(answer+'\\n\\n')\n",
    "                        f.write('gold'+ str(goldSent) + str(len(goldSent))+'\\n')\n",
    "                        f.write(str(goldTokens)+'\\n')\n",
    "                        f.write('pred' + str(tagsSent) + str(len(tagsSent))+'\\n')\n",
    "                        f.write(str(tokens)+'\\n')\n",
    "                        f.write('\\n\\n')\n",
    "                    tagsPred = ['None'] * len(goldSent)\n",
    "                    #dsdaasd\n",
    "                    break\n",
    "                resp = askGPT(prompt, temperature=temp)\n",
    "                answer = resp['choices'][0]['message']['content']\n",
    "                tries += 1\n",
    "                try:\n",
    "                    tokens = [token for token in answer.split(' ') if token[0] not in punctList]\n",
    "                    tokensSent = []\n",
    "                    tagsSent = []\n",
    "                    for token in tokens:\n",
    "                        if '/' in token:\n",
    "                            tagsSent.append(token.split('/')[1])\n",
    "                            tokensSent.append(token.split('/')[0])\n",
    "                        else:\n",
    "                            tagsSent.append('None')\n",
    "                            tokensSent.append(token)\n",
    "                except Exception as error:\n",
    "                    continue\n",
    "                idx = 0\n",
    "                erroIdx = 0\n",
    "                tagsPred = []\n",
    "                for token, tag in zip(goldTokens, goldSent):\n",
    "                    if idx >= len(tokensSent):\n",
    "                        tagsPred.append('None')\n",
    "                        erroIdx += 1\n",
    "                        continue           \n",
    "                    if tokensSent[idx].lower() == token.lower():\n",
    "                        tagsPred.append(tagsSent[idx])\n",
    "                    else:\n",
    "                        if idx == 0:\n",
    "                            while (tokensSent[idx].lower() != token.lower() and idx < 5):\n",
    "                                idx += 1\n",
    "                                if idx >= len(tokensSent):\n",
    "                                    idx -= 1\n",
    "                                    break\n",
    "                        if tokensSent[idx].lower() == token.lower():\n",
    "                            tagsPred.append(tagsSent[idx])\n",
    "                        else:\n",
    "                            tagsPred.append('None')\n",
    "                            erroIdx += 1\n",
    "                            continue\n",
    "                    idx += 1\n",
    "                if len(tagsPred) == len(goldSent) and erroIdx < 10:\n",
    "                    totalTries.append(tries)\n",
    "                    break\n",
    "        with open(fileName, 'w') as f:\n",
    "            json.dump(tagsPred, f)\n",
    "        pred += tagsPred\n",
    "        #ksdfhfkdh\n",
    "        #print('=======')\n",
    "    print('gold',len(gold),'pred',len(pred),'errors',errors)\n",
    "    with open(f'resultados/gpt_test_t{temp}.json', 'w') as f:\n",
    "        json.dump(pred, f)\n",
    "    #with open(f'resultados/gold.json', 'w') as f:\n",
    "    #    json.dump(gold, f)\n",
    "    print(metrics.classification_report(gold, pred))\n",
    "    print(\"\\n\\n\\n\\n######\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9957025e-78a2-4f74-b4d7-c2fab4b50b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None', 'None', 'None', 'None', 'None', 'None', 'None']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d370928b-d071-4758-8982-4a587d4ffd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Desculpe, mas não entendi o contexto ou a intenção por trás da repetição do texto. Posso ajudar com alguma outra coisa?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf23e053-764e-4a77-a844-2f6d941f3067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8Gvlsjc03Xo69uSqwe7mz8kaSE6Rk at 0x7faf5566b220> JSON: {\n",
       "  \"id\": \"chatcmpl-8Gvlsjc03Xo69uSqwe7mz8kaSE6Rk\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1699046012,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Desculpe, mas n\\u00e3o entendi o contexto ou a inten\\u00e7\\u00e3o por tr\\u00e1s da repeti\\u00e7\\u00e3o do texto. Posso ajudar com alguma outra coisa?\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 1205,\n",
       "    \"completion_tokens\": 33,\n",
       "    \"total_tokens\": 1238\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207902eb-4ff8-47be-9e70-512440db4bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28ade9-20c2-4cb8-88e9-0280b72eadbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ac168b5-1c51-49e2-beb9-7da39a35c919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'Atuando como linguista e sem efetuar correções ou alterações no texto'},\n",
       " {'role': 'user', 'content': 'O Capitão América também bajulou o tucano .'},\n",
       " {'role': 'system',\n",
       "  'content': 'O/DET Capitão/PROPN América/PROPN também/ADV bajulou/VERB o/DET tucano/NOUN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'A Odebrecht pagou 300 % a mais pelo por o direito de explorar o aeroporto do de o Galeão .'},\n",
       " {'role': 'system',\n",
       "  'content': 'A/DET Odebrecht/PROPN pagou/VERB 300/NUM %/SYM a/ADP mais/ADV pelo/None por/ADP o/DET direito/NOUN de/ADP explorar/VERB o/DET aeroporto/NOUN do/None de/ADP o/DET Galeão/PROPN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'No Em o começo do de o século , a JBS/Friboi chegava ao a o grupo das de as 400 maiores .'},\n",
       " {'role': 'system',\n",
       "  'content': 'No/None Em/ADP o/DET começo/NOUN do/None de/ADP o/DET século/NOUN ,/PUNCT a/DET JBS/Friboi/PROPN chegava/VERB ao/None a/ADP o/DET grupo/NOUN das/None de/ADP as/DET 400/NUM maiores/ADJ ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Os sons indesejáveis emitidos por uma porta , por exemplo , são eliminados por R$ 150 .'},\n",
       " {'role': 'system',\n",
       "  'content': 'Os/DET sons/NOUN indesejáveis/ADJ emitidos/VERB por/ADP uma/DET porta/NOUN ,/PUNCT por/ADP exemplo/NOUN ,/PUNCT são/AUX eliminados/VERB por/ADP R$/SYM 150/NUM ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Que foi herança do de o PT , que nos deixou esse rombo , disse Doria .'},\n",
       " {'role': 'system',\n",
       "  'content': 'Que/PRON foi/AUX herança/NOUN do/None de/ADP o/DET PT/PROPN ,/PUNCT que/PRON nos/PRON deixou/VERB esse/DET rombo/NOUN ,/PUNCT disse/VERB Doria/PROPN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'O departamento médico santista também já colocou o atleta para ter o acompanhamento de uma psicóloga .'},\n",
       " {'role': 'system',\n",
       "  'content': 'O/DET departamento/NOUN médico/ADJ santista/ADJ também/ADV já/ADV colocou/VERB o/DET atleta/NOUN para/ADP ter/VERB o/DET acompanhamento/NOUN de/ADP uma/DET psicóloga/NOUN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Por que é mais difícil para as mulheres lutar contra alcoolismo e dependência às a as drogas ?'},\n",
       " {'role': 'system',\n",
       "  'content': 'Por/ADP que/PRON é/AUX mais/ADV difícil/ADJ para/ADP as/DET mulheres/NOUN lutar/VERB contra/ADP alcoolismo/NOUN e/CCONJ dependência/NOUN às/None a/ADP as/DET drogas/NOUN ?/PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Outra etiqueta das de as mais clássicas do de o calendário , a Bottega Venetta construiu com base nas em as pintas de leopardo a imagem de amazona moderna .'},\n",
       " {'role': 'system',\n",
       "  'content': 'Outra/DET etiqueta/NOUN das/None de/ADP as/PRON mais/ADV clássicas/ADJ do/None de/ADP o/DET calendário/NOUN ,/PUNCT a/DET Bottega/PROPN Venetta/PROPN construiu/VERB com/ADP base/NOUN nas/None em/ADP as/DET pintas/NOUN de/ADP leopardo/NOUN a/DET imagem/NOUN de/ADP amazona/NOUN moderna/ADJ ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': 'Não é biodegradável e , para produzí-lo produzir lo , é necessário expandir ainda mais a agricultura da de a cana .'},\n",
       " {'role': 'system',\n",
       "  'content': 'Não/ADV é/AUX biodegradável/ADJ e/CCONJ ,/PUNCT para/ADP produzí-lo/None produzir/VERB lo/PRON ,/PUNCT é/AUX necessário/ADJ expandir/VERB ainda/ADV mais/ADV a/DET agricultura/NOUN da/None de/ADP a/DET cana/NOUN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': '\" Temos segurança de que ( ... ) são íntegros \" , diz o texto .'},\n",
       " {'role': 'system',\n",
       "  'content': '\"/PUNCT Temos/VERB segurança/NOUN de/ADP que/SCONJ (/PUNCT .../PUNCT )/PUNCT são/AUX íntegros/ADJ \"/PUNCT ,/PUNCT diz/VERB o/DET texto/NOUN ./PUNCT'},\n",
       " {'role': 'user',\n",
       "  'content': '\" Temos segurança de que ( ... ) são íntegros \" , diz o texto .Você , por exemplo , você brilha um pouco .'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5a484d-a093-4808-83e3-9e54c4a97b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf119e-02e2-4dfe-ab47-ac0c11c1cd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7edcf43-30bf-4c10-9562-cbc4dcce3a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8f519-f10a-4730-a33d-b4f3441aaf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctList = ['\"', ',', '.', '[', ']', '?','!']\n",
    "             #, '\"/PUNCT', ',/PUNCT', './PUNCT']\n",
    "#punctList = []\n",
    "for temp in range(6,10):\n",
    "    temp = temp/10\n",
    "    print('temp',temp)\n",
    "    gold = []\n",
    "    pred = []\n",
    "    totalTries = []\n",
    "    errors = 0\n",
    "    for revID, review in enumerate(tqdm(reviews[20:])):\n",
    "        prompt = promptStart\n",
    "        entrada = \"Entrada: \"\n",
    "        saida  = \"Saida: \"\n",
    "        goldSent = []\n",
    "        goldTokens = []\n",
    "        for token in review:\n",
    "            if not token[2]:\n",
    "                token[2] = 'None'\n",
    "            #print(token)\n",
    "            if token[0] not in punctList:\n",
    "                gold.append(token[2])\n",
    "                goldSent.append(token[2])\n",
    "                goldTokens.append(token[0])\n",
    "            entrada += token[0] + ' '\n",
    "            saida += token[0] + '/' + token[2] + ' '\n",
    "        entrada = entrada.strip()\n",
    "        saida = saida.strip()\n",
    "        prompt += entrada + \"\\nSaída: \"\n",
    "        #print(prompt)\n",
    "        #sdad\n",
    "        fileName = f'resultados/data/gpt_t{temp}_{revID}.json'\n",
    "        if os.path.isfile(fileName):\n",
    "            with open(fileName) as file:\n",
    "                tagsPred = json.load(file)\n",
    "        else:            \n",
    "            tries = 0\n",
    "            while True:\n",
    "                if tries > 10:\n",
    "                    errors += 1\n",
    "                    totalTries.append(tries)\n",
    "                    with open(f'resultados/data/gpt_erro_t{temp}_{revID}.log', 'w') as f:\n",
    "                        f.write(prompt)\n",
    "                        f.write('======')\n",
    "                        f.write(answer+'\\n\\n')\n",
    "                        f.write('gold'+ str(goldSent) + str(len(goldSent))+'\\n')\n",
    "                        f.write(str(goldTokens)+'\\n')\n",
    "                        f.write('pred' + str(tagsSent) + str(len(tagsSent))+'\\n')\n",
    "                        f.write(str(tokens)+'\\n')\n",
    "                        f.write('\\n\\n')\n",
    "                    tagsPred = ['None'] * len(goldSent)\n",
    "                    #dsdaasd\n",
    "                    break\n",
    "                answer = askLLM(prompt, temperature=temp)\n",
    "                tries += 1\n",
    "                try:\n",
    "                    tokens = [token for token in answer.split(' ') if token[0] not in punctList]\n",
    "                    tokensSent = []\n",
    "                    tagsSent = []\n",
    "                    for token in tokens:\n",
    "                        if '/' in token:\n",
    "                            tagsSent.append(token.split('/')[1])\n",
    "                            tokensSent.append(token.split('/')[0])\n",
    "                        else:\n",
    "                            tagsSent.append('None')\n",
    "                            tokensSent.append(token)\n",
    "                except Exception as error:\n",
    "                    continue\n",
    "                idx = 0\n",
    "                erroIdx = 0\n",
    "                tagsPred = []\n",
    "                for token, tag in zip(goldTokens, goldSent):\n",
    "                    if idx >= len(tokensSent):\n",
    "                        tagsPred.append('None')\n",
    "                        erroIdx += 1\n",
    "                        continue           \n",
    "                    if tokensSent[idx].lower() == token.lower():\n",
    "                        tagsPred.append(tagsSent[idx])\n",
    "                    else:\n",
    "                        if idx == 0:\n",
    "                            while (tokensSent[idx].lower() != token.lower() and idx < 5):\n",
    "                                idx += 1\n",
    "                                if idx >= len(tokensSent):\n",
    "                                    idx -= 1\n",
    "                                    break\n",
    "                        if tokensSent[idx].lower() == token.lower():\n",
    "                            tagsPred.append(tagsSent[idx])\n",
    "                        else:\n",
    "                            tagsPred.append('None')\n",
    "                            erroIdx += 1\n",
    "                            continue\n",
    "                    idx += 1\n",
    "                if len(tagsPred) == len(goldSent) and erroIdx < 10:\n",
    "                    totalTries.append(tries)\n",
    "                    break\n",
    "        with open(fileName, 'w') as f:\n",
    "            json.dump(tagsPred, f)\n",
    "        pred += tagsPred\n",
    "        #print('=======')\n",
    "    print('gold',len(gold),'pred',len(pred),'errors',errors)\n",
    "    with open(f'resultados/gpt_temp{temp}.json', 'w') as f:\n",
    "        json.dump(pred, f)\n",
    "    #with open(f'resultados/gold.json', 'w') as f:\n",
    "    #    json.dump(gold, f)\n",
    "    print(metrics.classification_report(gold, pred))\n",
    "    print(\"\\n\\n\\n\\n######\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a04e498f-2673-468a-8be3-ec18e1cdb914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "391b0615-feb5-4b76-ae2e-23183fc5c8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede869c-fc10-4758-a7eb-6faf64fdf162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebf732-a1ea-4afd-8099-e1ab5284983b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc4b58-39ec-42ab-bd51-e536dfec06f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130298b-0ac0-49f5-bd44-db2b6f857dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a23520-2400-4307-a8c2-f7b96b3a5666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729d970-412d-4453-b8c8-87beb99a5ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6f6b1fd-59f5-44a3-82a6-d20dcbe73970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Você', None, 'PRON', 'dislocated'],\n",
       "  [',', None, 'PUNCT', 'punct'],\n",
       "  ['por', None, 'ADP', 'case'],\n",
       "  ['exemplo', None, 'NOUN', 'obl'],\n",
       "  [',', None, 'PUNCT', 'punct'],\n",
       "  ['você', None, 'PRON', 'nsubj'],\n",
       "  ['brilha', None, 'VERB', 'root'],\n",
       "  ['um', None, 'DET', 'det'],\n",
       "  ['pouco', None, 'NOUN', 'obl'],\n",
       "  ['.', None, 'PUNCT', 'punct']],\n",
       " [['A', None, 'DET', 'det'],\n",
       "  ['gente', None, 'NOUN', 'nsubj'],\n",
       "  ['vai', None, 'AUX', 'aux'],\n",
       "  ['comprar', None, 'VERB', 'root'],\n",
       "  ['pão', None, 'NOUN', 'obj'],\n",
       "  ['e', None, 'CCONJ', 'cc'],\n",
       "  ['fica', None, 'VERB', 'conj'],\n",
       "  ['ouvindo', None, 'VERB', 'xcomp'],\n",
       "  ['muita', None, 'ADJ', 'amod'],\n",
       "  ['coisinha', None, 'NOUN', 'obj'],\n",
       "  ['.', None, 'PUNCT', 'punct']]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[20:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c79741b-1eb0-43f2-b2a4-fd68aa4b4bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta: A análise morfossintática é um processo de análise linguística que examina a estrutura das sentenças, identificando suas partes constituintes, como substantivos, verbos, adjetivos e preposições, e suas relações sintáticas entre si. A Universal Dependencies (UD) é um conjunto de regras de anotação que permite a representação dessas informações em uma forma padronizada.\n",
      "\n",
      "Aqui estão as análises morfossintáticas das frases fornecidas, utilizando a notação UD:\n",
      "\n",
      "Entrada: O Capitão América também bajulou o tucano .\n",
      "Saida: O/DET Capitão/PROPN América/PROPN também/ADV bajulou/VERB o/DET tucano/NOUN ./PUNCT\n",
      "\n",
      "Entrada: A Odebrecht pagou 300 % a mais pelo o direito de explorar o aeroporto do de o Galeão .\n",
      "Saida: A/DET Odebrecht/PROPN pagou/VERB 300/NUM %/SYM a/ADP mais/ADV pelo/None por/ADP o/DET direito/NOUN de/ADP explorar/VERB o/DET aeroporto/NOUN do/None de/ADP o/DET Galeão/PROPN ./PUNCT\n",
      "\n",
      "Entrada: No Em o começo do de o século , a JBS/Friboi chegava ao a o grupo das de as 400 maiores .\n",
      "Saida: No/None Em/ADP o/DET começo/NOUN do/None de/ADP o/DET século/NOUN ,/PUNCT a/DET JBS/Friboi/PROPN chegava/VERB ao/None a/ADP o/DET grupo/NOUN das/None de/ADP as/DET 400/NUM maiores/ADJ ./PUNCT\n",
      "\n",
      "Entrada: Os sons indesejáveis emitidos por uma porta , por exemplo , são eliminados por R$ 150 .\n",
      "Saida: Os/DET\n",
      "Resposta: A gente/DET vai/VERB comprar/VERB pão/NOUN e/CCONJ fica/VERB ouvindo/AUX muita/ADV coisinha/NOUN ./PUNCT\n"
     ]
    }
   ],
   "source": [
    "gold = []\n",
    "pred = []\n",
    "for review in reviews[20:22]:\n",
    "    prompt = promptStart\n",
    "    entrada = \"Entrada: \"\n",
    "    saida  = \"Saida: \"\n",
    "    for token in review:\n",
    "        if not token[2]:\n",
    "            token[2] = 'None'\n",
    "        gold.append(token[2])\n",
    "        entrada += token[0] + ' '\n",
    "        saida += token[0] + '/' + token[2] + ' '\n",
    "    entrada = entrada.strip()\n",
    "    saida = saida.strip()\n",
    "    prompt += entrada + \"\\nSaída: \"\n",
    "\n",
    "    answer = model.generate(prompt)\n",
    "    print(f\"Resposta: {answer}\")\n",
    "    print('=======')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ade0be5f-e388-41cd-935c-35ba2a3a2545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'PUNCT',\n",
       " 'ADP',\n",
       " 'NOUN',\n",
       " 'PUNCT',\n",
       " 'PRON',\n",
       " 'VERB',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'PUNCT',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'AUX',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'CCONJ',\n",
       " 'VERB',\n",
       " 'VERB',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237609dc-17e3-463e-9c0d-5539f5b81571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0b1719-a92b-4f50-9f2a-13efa35f231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maritaca_key =  os.getenv('MARITACA_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d2ec6d-afd4-4fe8-a860-95b3cdc946bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta: 25 + 27 = 52\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0a115ed-1641-40ce-8b81-2e89ca9159b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta: Mr./NNP Bean/NNP loves/VBZ giant/JJ bees/NNS ./.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Input: Ms. Haag plays Elianti .\n",
    "Output: Ms./NNP Haag/NNP plays/VBZ Elianti/NNP ./.\n",
    "\n",
    "Input: Mr. Bean loves giant bees.\n",
    "Output: \"\"\"\n",
    "answer = model.generate(prompt)\n",
    "print(f\"Resposta: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5fcaac-1536-41f1-88e1-7de72207dc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta: Mr./NNP Bean/NNP adora/VBZ abelhas/NNP gigantes/ADJ ./.\n",
      "\n",
      "Input: Ms. Bean adora abelhas gigantes.\n",
      "Output: Ms./NNP Bean/NNP adora/VBZ abelhas/NNP gigantes/ADJ ./.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Input: Ms. Haag plays Elianti .\n",
    "Output: Ms./NNP Haag/NNP plays/VBZ Elianti/NNP ./.\n",
    "\n",
    "Input: Mr. Bean adora abelhas gigantes.\n",
    "Output: \"\"\"\n",
    "answer = model.generate(prompt)\n",
    "print(f\"Resposta: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "930e24a9-d7e2-4eff-93d7-34f55b549252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta: Uma/DT bela/JJ casa/NN amarela/JJ .\n",
      "\n",
      "The second input you provided is a sentence in Portuguese, which is not a language I am capable of understanding or generating. If you have any questions or requests, please let me know and I'll do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Input: Ms. Haag plays Elianti .\n",
    "Output: Ms./NNP Haag/NNP plays/VBZ Elianti/NNP ./.\n",
    "\n",
    "Input: Uma bela casa amarela.\n",
    "Output: \"\"\"\n",
    "answer = model.generate(prompt)\n",
    "print(f\"Resposta: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51d919-cfc2-4f2f-b5a8-ee59ae5162ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
