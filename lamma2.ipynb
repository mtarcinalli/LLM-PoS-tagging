{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab10464-bb23-4e08-9014-2895ada3f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f5362-ebd4-4347-9415-98aa844810f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e32b99-646b-4c5b-b5c9-bb27642ac963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askLamma(prompt):\n",
    "    api_url = \"http://127.0.0.1:8042/llama/\"\n",
    "    todo = {\"prompts\":[prompt], \"max_gen_len\": 50}\n",
    "    response = requests.post(api_url, json=todo)\n",
    "    resp = response.json()\n",
    "    predicted_text = resp['responses'][0]['generation']\n",
    "    endOfAnswer = predicted_text.find('\\n')\n",
    "    return predicted_text[:endOfAnswer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62525703-e5e7-4a3c-9e81-a4b5de2c8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Bean/VBD loves/VBD giant bees/NNP ./.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Input: Ms. Haag plays Elianti .\n",
    "Output: Ms./NNP Haag/NNP plays/VBZ Elianti/NNP ./.\n",
    "\n",
    "Input: Mr. Bean loves giant bees.\n",
    "Output: \"\"\"\n",
    "print(askLamma(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa5f975-edfc-4a80-8f06-295ce9e728d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Input: Ms. Haag plays Elianti .\n",
    "Output: Ms./NNP Haag/NNP plays/VBZ Elianti/NNP ./.\n",
    "\n",
    "Input: Mr. Bean adora abelhas gigantes.\n",
    "Output: \"\"\"\n",
    "print(askLamma(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a83a33e-8340-423f-8a89-ef868ce02e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uma/NNP bela/NNP casa/NNP amarela/NNP ./.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Input: Ms. Haag plays Elianti .\n",
    "Output: Ms./NNP Haag/NNP plays/VBZ Elianti/NNP ./.\n",
    "\n",
    "Input: Uma bela casa amarela.\n",
    "Output: \"\"\"\n",
    "print(askLamma(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fed6b-9daf-40f6-9c8d-7b035fd007bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e034b5-43ab-4b6d-85e7-2b68c6315046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c30e8a-0266-46b4-9e02-8663a8a1467f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propor2023",
   "language": "python",
   "name": "propor2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
